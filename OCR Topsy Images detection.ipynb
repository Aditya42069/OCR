{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a51dcf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from skimage import io, transform\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential,layers\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e2e3d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size=149\n",
    "testing_size=50\n",
    "training_file_name=np.array(['./training_data/images/ ('+str(i)+').png' for i in range(1,training_size+1)])\n",
    "testing_file_name=np.array(['./testing_data/images/ ('+str(i)+').png' for i in range(1,testing_size+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a197d51",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e09c4510",
   "metadata": {},
   "outputs": [],
   "source": [
    "class metaDataLoader:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def blurFft(self,image):\n",
    "        size=60\n",
    "        (h, w) = image.shape\n",
    "        (cX, cY) = (int(w / 2.0), int(h / 2.0))\n",
    "        fft = np.fft.fft2(image)\n",
    "        fftShift = np.fft.fftshift(fft)\n",
    "        fftShift[cY - size:cY + size, cX - size:cX + size] = 0\n",
    "        fftShift = np.fft.ifftshift(fftShift)\n",
    "        recon = np.fft.ifft2(fftShift)\n",
    "        magnitude = 20 * np.log(np.abs(recon))\n",
    "        mean = np.mean(magnitude)\n",
    "        return mean\n",
    "    \n",
    "    def blurLaplacian(self,image):\n",
    "        return cv2.Laplacian(image, cv2.CV_64F).var()\n",
    "    \n",
    "    def morphologicalDilation(self,img):\n",
    "        if(np.max(img)<=1):\n",
    "            img=np.uint8(img*255)\n",
    "        img[img<=205]=0\n",
    "        img[img>205]=255\n",
    "        th = cv2.threshold(img,0,255,cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "        black = np.zeros([img.shape[0] + 2, img.shape[1] + 2], np.uint8)\n",
    "        mask = cv2.floodFill(th.copy(), black, (0,0), 0, 0, 0, flags=8)[1]\n",
    "        mask = cv2.floodFill(mask.copy(), black, (img.shape[1]-1,img.shape[0]-1), 0, 0, 0, flags=8)[1]\n",
    "        mask = cv2.floodFill(mask.copy(), black, (0,img.shape[0]-1), 0, 0, 0, flags=8)[1]\n",
    "        mask = cv2.floodFill(mask.copy(), black, (img.shape[1]-1,0), 0, 0, 0, flags=8)[1]\n",
    "        kernel_length = 30\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length, 1))\n",
    "        dilate = cv2.dilate(mask, horizontal_kernel, iterations=1)\n",
    "        return dilate\n",
    "    \n",
    "    def blurMeta(self, image):\n",
    "        return np.array([self.blurFft(image),self.blurLaplacian(image)])\n",
    "\n",
    "    def rotationMeta(self,image):\n",
    "        dilate=self.morphologicalDilation(image)\n",
    "        tested_angles = np.linspace(-np.pi / 2, np.pi / 2, 360, endpoint=False)\n",
    "        h, theta, d = transform.hough_line(dilate, theta=tested_angles)\n",
    "        _,angles,_=transform.hough_line_peaks(h, theta, d)\n",
    "        angles=[i*180/np.pi for i in angles]\n",
    "        pred_angle=90-abs(np.median(angles))\n",
    "        return np.array([pred_angle if np.median(angles)>0 else -1*pred_angle])\n",
    "        \n",
    "    def cropMeta(self,image,angle):\n",
    "        image=transform.rotate(image,-1*angle[0])\n",
    "        image=np.uint8(image*255)\n",
    "        dilate=self.morphologicalDilation(image)\n",
    "        contours=cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours=contours[0] if len(contours) == 2 else contours[1]\n",
    "        bounding_rects=[cv2.boundingRect(i) for i in contours]\n",
    "        if len(bounding_rects)!=0:\n",
    "            areas=[i[2]*i[3] for i in bounding_rects]\n",
    "            sorted_areas=sorted(areas)\n",
    "            x=-1\n",
    "            if sorted_areas[-1]==image.shape[0]*image.shape[1]:\n",
    "                x=-2\n",
    "            rect=bounding_rects[areas.index(sorted_areas[x])]\n",
    "            meta_data=[rect[0],rect[1],image.shape[0]-rect[0]-rect[2],image.shape[1]-rect[1]-rect[3]]\n",
    "        else:\n",
    "            meta_data=[-1,-1,-1,-1]\n",
    "        return np.array(meta_data)\n",
    "    \n",
    "    def getMetaData(self,image):\n",
    "        if(len(image.shape)>2):\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        blurMetaData=self.blurMeta(image)\n",
    "        rotMetaData=self.rotationMeta(image)\n",
    "        cropMetaData=self.cropMeta(image,rotMetaData)\n",
    "        return {\n",
    "            'Blur':blurMetaData,\n",
    "            'Rotation':rotMetaData,\n",
    "            'Crop':cropMetaData\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4174cfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataLoader(metaDataLoader):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        pass\n",
    "    \n",
    "    def imageAugmentation(self,img):\n",
    "        shape=img.shape\n",
    "        blur_filter_size=np.random.randint(10,50,2)\n",
    "        img=cv2.blur(img,blur_filter_size) \n",
    "        rotation_angle=(np.random.randint(0,1)-1)*(np.random.randint(15,90))\n",
    "        img=transform.rotate(img,rotation_angle)\n",
    "        size=[np.random.randint(shape[0]//2,shape[0]),np.random.randint(shape[1]//2,shape[1])]\n",
    "        img=tf.image.random_crop(img, size).numpy()\n",
    "        return img\n",
    "    \n",
    "    def loadImage(self,file_name,resize=None):\n",
    "        image=io.imread(file_name)\n",
    "        if resize:\n",
    "            image=transform.resize(image,output_shape=resize)\n",
    "        return image\n",
    "    \n",
    "    def generateDataset(self,file_names,resize=None):\n",
    "        splited_dataset=train_test_split(file_names,test_size=.5)\n",
    "        labels=np.concatenate([np.zeros(len(splited_dataset[0])),np.ones(len(splited_dataset[1]))])\n",
    "        features=[]\n",
    "        splited_dataset=np.concatenate(splited_dataset)\n",
    "        for i in tqdm(range(len(splited_dataset))):\n",
    "            image=self.loadImage(splited_dataset[i],resize)\n",
    "            if labels[i]==1:\n",
    "                image=self.imageAugmentation(image)\n",
    "            features.append(np.concatenate(list(self.getMetaData(image).values())))\n",
    "        features,labels=shuffle(features,labels)\n",
    "        features=np.array(features)                         \n",
    "        labels=np.array(labels)\n",
    "        return features,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b703d2",
   "metadata": {},
   "source": [
    "## Loading training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b902965",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader=dataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecc18eb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████▋           | 128/149 [03:47<00:30,  1.47s/it]C:\\Users\\adity\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\adity\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_2988\\1774208387.py:51: RuntimeWarning: invalid value encountered in cast\n",
      "  image=np.uint8(image*255)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 149/149 [04:06<00:00,  1.65s/it]\n"
     ]
    }
   ],
   "source": [
    "train_features,train_labels=loader.generateDataset(training_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46d30e74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|██████████████████████████████████████████████████████████████████████▌           | 43/50 [01:20<00:08,  1.20s/it]C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_2988\\1774208387.py:51: RuntimeWarning: invalid value encountered in cast\n",
      "  image=np.uint8(image*255)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [01:27<00:00,  1.74s/it]\n"
     ]
    }
   ],
   "source": [
    "test_features,test_labels=loader.generateDataset(testing_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e53e61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=np.nan_to_num(train_features)\n",
    "test_features=np.nan_to_num(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3a5f53",
   "metadata": {},
   "source": [
    "## Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d99329c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "    layers.Dense(7,input_shape=(7,),activation='linear'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(3,activation='linear'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1,activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98b34fbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 3s 10ms/step - loss: 1056.0287 - accuracy: 0.3893\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 978.7627 - accuracy: 0.3826\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 1011.9347 - accuracy: 0.4228\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 789.2164 - accuracy: 0.4027\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 753.0505 - accuracy: 0.3691\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 759.4157 - accuracy: 0.4295\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 710.9442 - accuracy: 0.4899\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 673.0383 - accuracy: 0.4295\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 757.0835 - accuracy: 0.4899\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 658.2606 - accuracy: 0.4698\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 535.0941 - accuracy: 0.4631\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 522.0367 - accuracy: 0.5235\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 402.2421 - accuracy: 0.5101\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 429.1833 - accuracy: 0.4765\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 552.1891 - accuracy: 0.4497\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 553.9295 - accuracy: 0.4765\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 601.4716 - accuracy: 0.4899\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 378.0786 - accuracy: 0.5034\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 7ms/step - loss: 379.5747 - accuracy: 0.4430\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 447.8623 - accuracy: 0.5034\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 374.0556 - accuracy: 0.5705\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 261.8548 - accuracy: 0.5369\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 337.8431 - accuracy: 0.6040\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 212.9441 - accuracy: 0.5436\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 178.6602 - accuracy: 0.5839\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 249.4334 - accuracy: 0.6040\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 221.3507 - accuracy: 0.6309\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 208.5721 - accuracy: 0.5772\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 235.2524 - accuracy: 0.6107\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 300.3063 - accuracy: 0.6309\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 272.1854 - accuracy: 0.5772\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 160.9972 - accuracy: 0.5973\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 245.2350 - accuracy: 0.5973\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 256.9631 - accuracy: 0.5906\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 160.5502 - accuracy: 0.5772\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 120.2499 - accuracy: 0.6779\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 108.3652 - accuracy: 0.6040\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 169.1536 - accuracy: 0.5772\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 228.5622 - accuracy: 0.6510\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 116.8443 - accuracy: 0.6242\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 203.2025 - accuracy: 0.5906\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 149.0903 - accuracy: 0.6510\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 200.0176 - accuracy: 0.5906\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 149.9994 - accuracy: 0.6711\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 73.4853 - accuracy: 0.6779\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 120.4037 - accuracy: 0.6174\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 186.6444 - accuracy: 0.5839\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 114.5655 - accuracy: 0.6510\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 110.7130 - accuracy: 0.6913\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 71.1767 - accuracy: 0.7047\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 140.0638 - accuracy: 0.6376\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 111.2189 - accuracy: 0.6443\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 98.3442 - accuracy: 0.7047\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 97.2339 - accuracy: 0.7114\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 38.9618 - accuracy: 0.7718\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 95.1546 - accuracy: 0.7450\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 84.7432 - accuracy: 0.6577\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 114.8847 - accuracy: 0.6846\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 81.4475 - accuracy: 0.7315\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 91.8633 - accuracy: 0.6779\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 153.9646 - accuracy: 0.6711\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 90.3648 - accuracy: 0.6443\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 52.9206 - accuracy: 0.7114\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 107.1441 - accuracy: 0.6510\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 68.6273 - accuracy: 0.7114\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 77.9419 - accuracy: 0.7517\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 103.0183 - accuracy: 0.7383\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 32.0434 - accuracy: 0.7651\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 29.1521 - accuracy: 0.8389\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 79.2263 - accuracy: 0.7517\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.9249 - accuracy: 0.7785\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 69.2191 - accuracy: 0.7450\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 92.6858 - accuracy: 0.7383\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 64.6189 - accuracy: 0.7517\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 22.3615 - accuracy: 0.7584\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 103.2298 - accuracy: 0.7785\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 43.1037 - accuracy: 0.7852\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 50.4666 - accuracy: 0.7651\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 52.8603 - accuracy: 0.7718\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 42.8194 - accuracy: 0.7315\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 28.6246 - accuracy: 0.8121\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 69.9214 - accuracy: 0.7383\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 5ms/step - loss: 89.5782 - accuracy: 0.7517\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 76.8736 - accuracy: 0.7047\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 14.0673 - accuracy: 0.8188\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 79.8832 - accuracy: 0.7785\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 57.0380 - accuracy: 0.7718\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 45.1502 - accuracy: 0.7852\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 32.1468 - accuracy: 0.7651\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 77.0012 - accuracy: 0.7517\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 86.6491 - accuracy: 0.7315\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 51.1149 - accuracy: 0.8255\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 37.6426 - accuracy: 0.8188\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 64.8734 - accuracy: 0.8054\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 14.3782 - accuracy: 0.8054\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 28.0353 - accuracy: 0.8188\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 47.6901 - accuracy: 0.8389\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 32.1108 - accuracy: 0.8121\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 36.9796 - accuracy: 0.7584\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 53.7222 - accuracy: 0.7785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1743f7248d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_features,train_labels,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01cadf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 18ms/step - loss: 6.9607e-13 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.960704256910033e-13, 1.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_features,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2509bfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "model_pred=model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b900abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred=[int(i[0]) for i in model_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fa80fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        25\n",
      "         1.0       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        50\n",
      "   macro avg       1.00      1.00      1.00        50\n",
      "weighted avg       1.00      1.00      1.00        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels,model_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa65089",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7e43e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv=SVC()\n",
    "sv.fit(train_features,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "246ca8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=sv.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbab66d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        25\n",
      "         1.0       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        50\n",
      "   macro avg       1.00      1.00      1.00        50\n",
      "weighted avg       1.00      1.00      1.00        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821b3ada",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c08d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82ab4bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(train_features,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "734065ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2=tree.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1916e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        25\n",
      "         1.0       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        50\n",
      "   macro avg       1.00      1.00      1.00        50\n",
      "weighted avg       1.00      1.00      1.00        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels,pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda9cff4",
   "metadata": {},
   "source": [
    "## Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f49f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ANN.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75fd94e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2eb4dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SVC.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(sv,\"SVC.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aef7783d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DTC.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(tree,\"DTC.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec733f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
